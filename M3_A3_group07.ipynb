{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Validation and Hyperparameter Tuning\n",
    "\n",
    "##### Dataset\n",
    "You will use the Credit Approval Dataset from the UCI Machine Learning Repository. Each row represents a credit application with 16 attributes:\n",
    "\n",
    "- A1 to A15 → Predictor variables (some categorical, some numerical, with missing values).\n",
    "- A16 → Target variable (approved (+) or denied (-)).\n",
    "\n",
    "You can find the dataset on Microsoft Teams.\n",
    "\n",
    "#### 1. Data Loading and Cleaning\n",
    "\n",
    "- Load the dataset into a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Identify and handle missing values appropriately (e.g., using imputation techniques)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Convert categorical variables into numerical format (e.g., label encoding or one-hot encoding)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Scale numerical features if necessary (e.g., StandardScaler, MinMaxScaler) and explain why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Exploratory Data Analysis (EDA) – Focus on Visualization\n",
    "\n",
    "\n",
    "Since we have not covered statistical analysis in detail, focus on visualizing the dataset:\n",
    "\n",
    "- Distribution of features: Use histograms to explore numerical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Target variable distribution: Use a bar chart to show the proportion of approved vs. denied applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Feature relationships: Use scatter plots, pair plots, or correlation heatmaps to explore potential relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Model Building and Evaluation\n",
    "\n",
    "\n",
    "<b>Step 1: Data Splitting</b>\n",
    "- Split the dataset into training (80%) and testing (20%) sets.\n",
    "- Keep the test set separate for final evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Step 2: Model Training & Cross-Validation</b>\n",
    "- Train at least two classification models (e.g., Logistic Regression, Decision Tree, k-NN).\n",
    "- Use cross-validation on the training set to evaluate model performance (e.g., accuracy, precision, recall, F1-score).\n",
    "- Identify the best-performing model based on cross-validation results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Step 3: Final Model Evaluation</b>\n",
    "- Train the best model on the full training data.\n",
    "- Evaluate the model on the test set using accuracy and a classification report.\n",
    "- Compare cross-validation results with the test set performance to check for overfitting or underfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>(Optional) Step 4: Hyperparameter Tuning</b>\n",
    "- If time permits, use GridSearchCV or RandomizedSearchCV to optimize the best model.\n",
    "- Report any improvements after tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Interpretation & Conclusion\n",
    "\n",
    "\n",
    "- Summarize key insights from the analysis and model evaluation.\n",
    "- Discuss the performance of your best model and whether it is suitable for credit approval predictions.\n",
    "- Highlight any potential bias or limitations in the dataset."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
